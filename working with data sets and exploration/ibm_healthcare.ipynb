{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement : Janatahack: Healthcare Analytics II\n",
        "\n",
        "Recent Covid-19 Pandemic has raised alarms over one of the most overlooked area to focus: Healthcare Management. While healthcare management has various use cases for using data science, patient length of stay is one critical parameter to observe and predict if one wants to improve the efficiency of the healthcare management in a hospital. \n",
        "\n",
        "This parameter helps hospitals to identify patients of high LOS risk (patients who will stay longer) at the time of admission. Once identified, patients with high LOS risk can have their treatment plan optimized to miminize LOS and lower the chance of staff/visitor infection. Also, prior knowledge of LOS can aid in logistics such as room and bed allocation planning.\n",
        "\n",
        "Suppose you have been hired as Data Scientist of HealthMan – a not for profit organization dedicated to manage the functioning of Hospitals in a professional and optimal manner.\n",
        "The task is to accurately predict the Length of Stay for each patient on case by case basis so that the Hospitals can use this information for optimal resource allocation and better functioning. The length of stay is divided into 11 different classes ranging from 0-10 days to more than 100 days.\n",
        "\n",
        " \n",
        "\n",
        "Data Description\n",
        "\n",
        "\n",
        "Train.zip contains 1 csv alongside the data dictionary that contains definitions for each variable\n",
        "\n",
        "train.csv – File containing features related to patient, hospital and Length of stay on case basis\n",
        "\n",
        "train_data_dict.csv – File containing the information of the features in train file\n",
        "\n",
        "\n",
        "\n",
        "Test Set\n",
        "\n",
        "test.csv – File containing features related to patient, hospital. Need to predict the Length of stay for each case_id\n",
        "\n",
        "\n",
        "\n",
        "Sample Submission:\n",
        "\n",
        "case_id: Unique id for each case\n",
        "\n",
        "Stay: Length of stay for the patient w.r.t each case id in test data"
      ],
      "metadata": {
        "id": "DE6k5xBYVKZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATASET can be downloaded here -> https://www.kaggle.com/vetrirah/av-healthcare2/"
      ],
      "metadata": {
        "id": "HfhOhqPbVKZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCpk-qq_WoiF",
        "outputId": "98cc4ea8-7335-4d65-97ab-99ed5d065690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold,StratifiedKFold,RepeatedStratifiedKFold\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# import eli5\n",
        "# from eli5.sklearn import PermutationImportance\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "764HbHVVVKZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df      = pd.read_csv('/content/drive/MyDrive/Pitt/ibm/train.csv')\n",
        "test_df       =  pd.read_csv('/content/drive/MyDrive/Pitt/ibm/test.csv')\n",
        "submission_df = pd.read_csv('/content/drive/MyDrive/Pitt/ibm/sample_submission.csv')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "O4RxA_DdVKZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Addition Features\n",
        "combine_set=pd.concat([train_df,test_df],axis=0)\n",
        "combine_set['City_Code_Patient'].fillna(-99,inplace=True)\n",
        "combine_set['Bed Grade'].fillna(5,inplace=True)\n",
        "combine_set['Unique_Hospital_per_patient']=combine_set.groupby(['patientid'])['Hospital_code'].transform('nunique')\n",
        "combine_set['Unique_patient_per_hospital']=combine_set.groupby(['Hospital_code'])['patientid'].transform('nunique')\n",
        "combine_set['Unique_patient_per_Department']=combine_set.groupby(['Department'])['patientid'].transform('nunique')\n",
        "combine_set['Total_deposit_paid_by_patient_in_each_hospital']=combine_set.groupby(['Hospital_code','patientid'])['Admission_Deposit'].transform('sum')\n",
        "combine_set['Min_Severity_of_Illness'] = combine_set.groupby('patientid')['Severity of Illness'].transform('min')"
      ],
      "metadata": {
        "trusted": true,
        "id": "o_C0lTuIVKZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In[4]:\n",
        "\n",
        "le = LabelEncoder()\n",
        "#Encoding categorical variables by frequency encoding and label encoding\n",
        "for col in combine_set.select_dtypes(include='object').columns:\n",
        "    if col not in ['Age','Stay']:\n",
        "        fe=combine_set.groupby([col]).size()/len(combine_set)\n",
        "        combine_set[col]=combine_set[col].apply(lambda x: fe[x])   \n",
        "        # combine_set[col]  = pd.get_dummies(combine_set[col].astype(str))         \n",
        "    elif col!='Stay':\n",
        "        combine_set[col]=le.fit_transform(combine_set[col].astype(str))\n",
        "    else:\n",
        "        pass"
      ],
      "metadata": {
        "trusted": true,
        "id": "8vCpLyJ-VKZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In[5]:\n",
        "\n",
        "#Splitting train and test\n",
        "\n",
        "X=combine_set[combine_set['Stay'].isnull()==False].drop(['case_id','Stay'],axis=1)\n",
        "y=le.fit_transform(combine_set[combine_set['Stay'].isnull()==False]['Stay'])\n",
        "y=pd.DataFrame(y,columns=['Stay'])\n",
        "X_main_test=combine_set[combine_set['Stay'].isnull()==True].drop(['case_id','Stay'],axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "weIDafp9VKZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In[6]:\n",
        "\n",
        "# kf=KFold(n_splits=10,shuffle=True,random_state=294)\n",
        "kf=KFold(n_splits=5,shuffle=True)\n",
        "\n",
        "preds_1   = {}\n",
        "y_pred_1  = []\n",
        "acc_score = []\n",
        "\n",
        "for i,(train_idx,val_idx) in enumerate(kf.split(X)):    \n",
        "    \n",
        "    X_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx]\n",
        "    \n",
        "    X_val, y_val = X.iloc[val_idx, :], y.iloc[val_idx]\n",
        "   \n",
        "    print('\\nFold: {}\\n'.format(i+1))\n",
        "\n",
        "    lg=LGBMClassifier( \n",
        "                      gpu_platform_id= 0,\n",
        "                      max_bin=63,#Theoretically best speeds using LGBM\n",
        "                      gpu_device_id= 0,\n",
        "                      boosting_type='gbdt',\n",
        "                      learning_rate=0.04,\n",
        "                      # max_depth=15,\n",
        "                      # num_leaves = 150,\n",
        "                      objective='multi_class',\n",
        "                      num_class=11,                      \n",
        "                      n_estimators=50000,\n",
        "                      metric='multi_error',\n",
        "                      colsample_bytree=0.8,\n",
        "                      min_child_samples=228,\n",
        "                      reg_alpha=1,\n",
        "                      reg_lambda=1,\n",
        "                      # random_state=294,\n",
        "                      n_jobs=-1,\n",
        "                     \n",
        "                      ) \n",
        "    \n",
        "    # lg.fit(X_train,y_train)\n",
        "    lg.fit(X_train, y_train\n",
        "#                         ,categorical_feature = categorical_features\n",
        "                        ,eval_metric='multi_error'\n",
        "                        ,eval_set=[(X_train, y_train),(X_val, y_val)]\n",
        "                        ,early_stopping_rounds=100\n",
        "                        ,verbose=50\n",
        "                       )\n",
        "    \n",
        "    print(accuracy_score(y_val,lg.predict(X_val))*100)\n",
        "    \n",
        "    acc = accuracy_score(y_val,lg.predict(X_val))*100\n",
        "    acc_score.append(acc)\n",
        "    print(\"Score : \",acc)    \n",
        "    y_pred_1.append(lg.predict_proba(X_main_test))\n",
        "    \n",
        "    # preds_1[i+1]=lg.predict_proba(X_main_test)\n",
        "    # y_pred_1.append(lg.predict_proba(X_main_test))\n",
        "\n",
        "y_pred_final_1          = np.mean(np.array(y_pred_1),axis=0)\n",
        "    \n",
        "print('mean accuracy score: {}'.format((sum(acc_score)/10)))\n",
        "\n",
        "preds_1=np.argmax(y_pred_final_1,axis=1)\n",
        "\n",
        "print(preds_1.shape)\n",
        "submission_df['Stay']=le.inverse_transform(preds_1.astype(int))\n",
        "# submission_df[0] = y_pred_final_1[:,0]\n",
        "# submission_df[1] =y_pred_final_1[:,1]\n",
        "\n",
        "# Download Submission File :\n",
        "display(\"submission_df\",submission_df)\n",
        "sub_file_name_1 = \"BEST_11_CV=42.96_LB=WAIT_LGBM-1.csv\"\n",
        "\n",
        "submission_df.to_csv(sub_file_name_1,index=False)\n",
        "submission_df.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM3rDQYsVKZf",
        "outputId": "c4c3de6b-248a-400a-c2aa-c58718f4b5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold: 1\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\ttraining's multi_error: 0.586151\tvalid_1's multi_error: 0.587991\n",
            "[100]\ttraining's multi_error: 0.57591\tvalid_1's multi_error: 0.580737\n",
            "[150]\ttraining's multi_error: 0.571859\tvalid_1's multi_error: 0.576796\n",
            "[200]\ttraining's multi_error: 0.568236\tvalid_1's multi_error: 0.574818\n",
            "[250]\ttraining's multi_error: 0.565134\tvalid_1's multi_error: 0.572965\n",
            "[300]\ttraining's multi_error: 0.562065\tvalid_1's multi_error: 0.57229\n",
            "[350]\ttraining's multi_error: 0.559066\tvalid_1's multi_error: 0.572117\n",
            "[400]\ttraining's multi_error: 0.556777\tvalid_1's multi_error: 0.571662\n",
            "[450]\ttraining's multi_error: 0.554453\tvalid_1's multi_error: 0.570531\n",
            "[500]\ttraining's multi_error: 0.55211\tvalid_1's multi_error: 0.570013\n",
            "[550]\ttraining's multi_error: 0.549798\tvalid_1's multi_error: 0.569464\n",
            "[600]\ttraining's multi_error: 0.547772\tvalid_1's multi_error: 0.569197\n",
            "[650]\ttraining's multi_error: 0.545782\tvalid_1's multi_error: 0.569118\n",
            "[700]\ttraining's multi_error: 0.543623\tvalid_1's multi_error: 0.568914\n",
            "[750]\ttraining's multi_error: 0.541723\tvalid_1's multi_error: 0.568317\n",
            "[800]\ttraining's multi_error: 0.539745\tvalid_1's multi_error: 0.567831\n",
            "[850]\ttraining's multi_error: 0.537923\tvalid_1's multi_error: 0.567831\n",
            "[900]\ttraining's multi_error: 0.536035\tvalid_1's multi_error: 0.567595\n",
            "[950]\ttraining's multi_error: 0.534446\tvalid_1's multi_error: 0.567187\n",
            "[1000]\ttraining's multi_error: 0.532502\tvalid_1's multi_error: 0.567281\n",
            "[1050]\ttraining's multi_error: 0.530724\tvalid_1's multi_error: 0.566967\n",
            "[1100]\ttraining's multi_error: 0.528958\tvalid_1's multi_error: 0.567046\n",
            "[1150]\ttraining's multi_error: 0.527278\tvalid_1's multi_error: 0.566653\n",
            "[1200]\ttraining's multi_error: 0.525696\tvalid_1's multi_error: 0.566779\n",
            "[1250]\ttraining's multi_error: 0.524004\tvalid_1's multi_error: 0.566261\n",
            "[1300]\ttraining's multi_error: 0.522375\tvalid_1's multi_error: 0.565868\n",
            "[1350]\ttraining's multi_error: 0.520573\tvalid_1's multi_error: 0.566213\n",
            "[1400]\ttraining's multi_error: 0.518952\tvalid_1's multi_error: 0.566402\n",
            "Early stopping, best iteration is:\n",
            "[1323]\ttraining's multi_error: 0.521602\tvalid_1's multi_error: 0.565774\n",
            "43.42262278608215\n",
            "Score :  43.42262278608215\n",
            "\n",
            "Fold: 2\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\ttraining's multi_error: 0.585539\tvalid_1's multi_error: 0.587458\n",
            "[100]\ttraining's multi_error: 0.575843\tvalid_1's multi_error: 0.580408\n",
            "[150]\ttraining's multi_error: 0.571042\tvalid_1's multi_error: 0.577895\n",
            "[200]\ttraining's multi_error: 0.567533\tvalid_1's multi_error: 0.57543\n",
            "[250]\ttraining's multi_error: 0.56422\tvalid_1's multi_error: 0.57452\n",
            "[300]\ttraining's multi_error: 0.561339\tvalid_1's multi_error: 0.574001\n",
            "[350]\ttraining's multi_error: 0.558975\tvalid_1's multi_error: 0.572745\n",
            "[400]\ttraining's multi_error: 0.556718\tvalid_1's multi_error: 0.57207\n",
            "[450]\ttraining's multi_error: 0.554748\tvalid_1's multi_error: 0.571536\n",
            "[500]\ttraining's multi_error: 0.552514\tvalid_1's multi_error: 0.571442\n",
            "[550]\ttraining's multi_error: 0.550449\tvalid_1's multi_error: 0.571159\n",
            "[600]\ttraining's multi_error: 0.54829\tvalid_1's multi_error: 0.571458\n",
            "[650]\ttraining's multi_error: 0.546422\tvalid_1's multi_error: 0.571002\n",
            "[700]\ttraining's multi_error: 0.544122\tvalid_1's multi_error: 0.570312\n",
            "[750]\ttraining's multi_error: 0.542347\tvalid_1's multi_error: 0.570469\n",
            "[800]\ttraining's multi_error: 0.540322\tvalid_1's multi_error: 0.57006\n",
            "[850]\ttraining's multi_error: 0.538654\tvalid_1's multi_error: 0.569448\n",
            "[900]\ttraining's multi_error: 0.536785\tvalid_1's multi_error: 0.569731\n",
            "[950]\ttraining's multi_error: 0.534936\tvalid_1's multi_error: 0.569291\n",
            "[1000]\ttraining's multi_error: 0.533382\tvalid_1's multi_error: 0.569212\n",
            "[1050]\ttraining's multi_error: 0.531282\tvalid_1's multi_error: 0.569118\n",
            "[1100]\ttraining's multi_error: 0.529763\tvalid_1's multi_error: 0.569322\n",
            "Early stopping, best iteration is:\n",
            "[1031]\ttraining's multi_error: 0.532149\tvalid_1's multi_error: 0.569008\n",
            "43.09917095842231\n",
            "Score :  43.09917095842231\n",
            "\n",
            "Fold: 3\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\ttraining's multi_error: 0.585354\tvalid_1's multi_error: 0.590362\n",
            "[100]\ttraining's multi_error: 0.575321\tvalid_1's multi_error: 0.583469\n",
            "[150]\ttraining's multi_error: 0.570767\tvalid_1's multi_error: 0.580345\n",
            "[200]\ttraining's multi_error: 0.567427\tvalid_1's multi_error: 0.578084\n",
            "[250]\ttraining's multi_error: 0.564542\tvalid_1's multi_error: 0.576765\n",
            "[300]\ttraining's multi_error: 0.561413\tvalid_1's multi_error: 0.575148\n",
            "[350]\ttraining's multi_error: 0.558744\tvalid_1's multi_error: 0.5743\n",
            "[400]\ttraining's multi_error: 0.556306\tvalid_1's multi_error: 0.573452\n",
            "[450]\ttraining's multi_error: 0.553947\tvalid_1's multi_error: 0.573609\n",
            "[500]\ttraining's multi_error: 0.552039\tvalid_1's multi_error: 0.573373\n",
            "[550]\ttraining's multi_error: 0.549519\tvalid_1's multi_error: 0.572887\n",
            "[600]\ttraining's multi_error: 0.547533\tvalid_1's multi_error: 0.572714\n",
            "[650]\ttraining's multi_error: 0.545574\tvalid_1's multi_error: 0.572431\n",
            "[700]\ttraining's multi_error: 0.543466\tvalid_1's multi_error: 0.572416\n",
            "[750]\ttraining's multi_error: 0.541307\tvalid_1's multi_error: 0.572133\n",
            "[800]\ttraining's multi_error: 0.539344\tvalid_1's multi_error: 0.57207\n",
            "[850]\ttraining's multi_error: 0.537303\tvalid_1's multi_error: 0.571552\n",
            "[900]\ttraining's multi_error: 0.535576\tvalid_1's multi_error: 0.572007\n",
            "[950]\ttraining's multi_error: 0.533731\tvalid_1's multi_error: 0.572086\n",
            "Early stopping, best iteration is:\n",
            "[854]\ttraining's multi_error: 0.537131\tvalid_1's multi_error: 0.571458\n",
            "42.854226855922626\n",
            "Score :  42.854226855922626\n",
            "\n",
            "Fold: 4\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\ttraining's multi_error: 0.586506\tvalid_1's multi_error: 0.589539\n",
            "[100]\ttraining's multi_error: 0.575868\tvalid_1's multi_error: 0.58048\n",
            "[150]\ttraining's multi_error: 0.572057\tvalid_1's multi_error: 0.576821\n",
            "[200]\ttraining's multi_error: 0.567974\tvalid_1's multi_error: 0.57445\n",
            "[250]\ttraining's multi_error: 0.565011\tvalid_1's multi_error: 0.572786\n",
            "[300]\ttraining's multi_error: 0.562161\tvalid_1's multi_error: 0.571514\n",
            "[350]\ttraining's multi_error: 0.559578\tvalid_1's multi_error: 0.57076\n",
            "[400]\ttraining's multi_error: 0.557211\tvalid_1's multi_error: 0.57043\n",
            "[450]\ttraining's multi_error: 0.554867\tvalid_1's multi_error: 0.569959\n",
            "[500]\ttraining's multi_error: 0.552359\tvalid_1's multi_error: 0.570368\n",
            "[550]\ttraining's multi_error: 0.5502\tvalid_1's multi_error: 0.569551\n",
            "[600]\ttraining's multi_error: 0.548139\tvalid_1's multi_error: 0.569002\n",
            "[650]\ttraining's multi_error: 0.546149\tvalid_1's multi_error: 0.568452\n",
            "[700]\ttraining's multi_error: 0.543986\tvalid_1's multi_error: 0.568389\n",
            "[750]\ttraining's multi_error: 0.542173\tvalid_1's multi_error: 0.568059\n",
            "[800]\ttraining's multi_error: 0.540092\tvalid_1's multi_error: 0.567573\n",
            "[850]\ttraining's multi_error: 0.538593\tvalid_1's multi_error: 0.56751\n",
            "[900]\ttraining's multi_error: 0.536771\tvalid_1's multi_error: 0.567369\n",
            "[950]\ttraining's multi_error: 0.535193\tvalid_1's multi_error: 0.567227\n",
            "[1000]\ttraining's multi_error: 0.533274\tvalid_1's multi_error: 0.567102\n",
            "[1050]\ttraining's multi_error: 0.531134\tvalid_1's multi_error: 0.566992\n",
            "[1100]\ttraining's multi_error: 0.529199\tvalid_1's multi_error: 0.567212\n",
            "[1150]\ttraining's multi_error: 0.527633\tvalid_1's multi_error: 0.566945\n",
            "[1200]\ttraining's multi_error: 0.525851\tvalid_1's multi_error: 0.56685\n",
            "[1250]\ttraining's multi_error: 0.524269\tvalid_1's multi_error: 0.56707\n",
            "Early stopping, best iteration is:\n",
            "[1178]\ttraining's multi_error: 0.526628\tvalid_1's multi_error: 0.566552\n",
            "43.34479564118266\n",
            "Score :  43.34479564118266\n",
            "\n",
            "Fold: 5\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\ttraining's multi_error: 0.586031\tvalid_1's multi_error: 0.585598\n",
            "[100]\ttraining's multi_error: 0.576367\tvalid_1's multi_error: 0.57825\n",
            "[150]\ttraining's multi_error: 0.571527\tvalid_1's multi_error: 0.575926\n",
            "[200]\ttraining's multi_error: 0.567397\tvalid_1's multi_error: 0.573759\n",
            "[250]\ttraining's multi_error: 0.564492\tvalid_1's multi_error: 0.572236\n",
            "[300]\ttraining's multi_error: 0.561493\tvalid_1's multi_error: 0.571577\n",
            "[350]\ttraining's multi_error: 0.559052\tvalid_1's multi_error: 0.570776\n",
            "[400]\ttraining's multi_error: 0.556492\tvalid_1's multi_error: 0.570195\n",
            "[450]\ttraining's multi_error: 0.554192\tvalid_1's multi_error: 0.570116\n",
            "[500]\ttraining's multi_error: 0.551982\tvalid_1's multi_error: 0.569787\n",
            "[550]\ttraining's multi_error: 0.549749\tvalid_1's multi_error: 0.569787\n",
            "[600]\ttraining's multi_error: 0.547448\tvalid_1's multi_error: 0.569708\n",
            "[650]\ttraining's multi_error: 0.545541\tvalid_1's multi_error: 0.569645\n",
            "[700]\ttraining's multi_error: 0.543566\tvalid_1's multi_error: 0.569331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm --install-option -DUSE_GPU=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR6Mhoh9etes",
        "outputId": "ca4566f2-d84a-4d89-c4b6-7e97cb70c3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py:232: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->lightgbm) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tAflWb0Z99I",
        "outputId": "4c3a8828-f7a9-4dae-f84e-f9e78430994a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost                         import CatBoostClassifier\n",
        "import timeit\n",
        "\n",
        "catboost = CatBoostClassifier(eval_metric='Accuracy', max_depth=4, task_type=\"GPU\", devices=\"0:1\", n_estimators=1000, verbose=500)\n",
        "catboost.fit( X, y, verbose=10 )   \n",
        "y_pred_3  = []\n",
        "y_pred_3.append(catboost.predict_proba(X_main_test))\n",
        "y_pred_final_3          = np.mean(np.array(y_pred_3),axis=0)\n",
        "# gpu_time = timeit.timeit('train_on_gpu()', setup=\"from __main__ import train_on_gpu\", number=1)\n",
        "# print('Time to fit and predict model on GPU: {} sec'.format(int(gpu_time)))\n",
        "\n",
        "preds_3=np.argmax(y_pred_final_3,axis=1)\n",
        "\n",
        "submission_df['Stay']=le.inverse_transform(preds_3.astype(int))\n",
        "# submission_df[0] = y_pred_final_1[:,0]\n",
        "# submission_df[1] =y_pred_final_1[:,1]\n",
        "\n",
        "# Download Submission File :\n",
        "display(\"submission_df\",submission_df)\n",
        "sub_file_name_3 = \"BEST_11_CV=42.96_LB=WAIT_LGBM-1.csv\"\n",
        "\n",
        "submission_df.to_csv(sub_file_name_3,index=False)\n",
        "submission_df.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "y81F57S1VKZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble of LGBM + CatBoost :\n",
        "\n",
        "preds = (y_pred_final_1*0.2 + y_pred_final_3*0.8) /2\n",
        "preds=np.argmax(preds,axis=1)\n",
        "print(preds)\n",
        "\n",
        "# In[9]:\n",
        "# Download Submission File :\n",
        "submission_df['Stay']=le.inverse_transform(preds.astype(int))\n",
        "display(\"submission_df\",submission_df)\n",
        "sub_file_name = \"ENSEMBLE_1_CV=42.22_42.17_LB=WAIT_LGB-1_0.2_LBG-2_0.8.csv\"\n",
        "\n",
        "submission_df.to_csv(sub_file_name,index=False)\n",
        "submission_df.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dV4HscHYVKZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<center>😊 Reached Rank 30 in Public Leaderboard - Thanks for reading Friends. See you all in Part 2 for more Analysis and Modelling - ENCOURAGE if you liked this Notebook 😊</center>**\n",
        "\n",
        "### **<center>😊 For Learning Purpose - You can still participate in your free time to see your Public and Private Scores & Rank, though it won't reflect on Leaderboard 😊</center>**\n",
        "\n",
        "### **<center>😊 Ask your doubts & Share your thoughts, ideas & feedbacks in Comments below 😊</center>**"
      ],
      "metadata": {
        "id": "hGsDQtZzVKZh"
      }
    }
  ]
}